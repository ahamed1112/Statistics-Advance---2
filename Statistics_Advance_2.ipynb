{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jom8pg41jnSZ"
      },
      "outputs": [],
      "source": [
        "1.  What is hypothesis testing in statistics\n",
        "Ans - Hypothesis testing in statistics is a formal procedure used to make inferences or draw conclusions about a population based on sample data.\n",
        " It involves testing an assumption (called a hypothesis) to determine whether there is enough statistical evidence to support or reject it."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  What is the null hypothesis, and how does it differ from the alternative hypothesis?\n",
        "Ans - In statistics, hypothesis testing involves two competing statements: the null hypothesis and the alternative hypothesis. These hypotheses help in making objective decisions based on data.\n",
        " * The null hypothesis is the default assumption that there is no effect, no difference, or no relationship in the population.\n",
        " *The alternative hypothesis is what you want to prove or provide evidence for.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_lNL8EuQklVr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.  What is the significance level in hypothesis testing, and why is it important\n",
        "Ans - The significance level (Œ±) is the maximum allowable probability of making a Type I error in a statistical test. It reflects the degree of risk the researcher is willing to take in drawing a wrong conclusion.\n",
        "   It is importent because:\n",
        " *Decision-Making Threshold\n",
        " *Controls Error Rate\n",
        " *Reflects the Research Context\n"
      ],
      "metadata": {
        "id": "CDMhSwtElTLv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.  What does a P-value represent in hypothesis testing\n",
        "Ans - The P-value is the probability of obtaining the observed results, or more extreme results, assuming that the null hypothesis is true."
      ],
      "metadata": {
        "id": "XBgiRAXRl9z1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.  How do you interpret the P-value in hypothesis testing\n",
        "Ans - The P-value helps you decide whether to reject or fail to reject the null hypothesis (H‚ÇÄ). It measures the strength of evidence against H‚ÇÄ, based on your sample data.\n",
        "The P-value is the probability of getting the observed result (or something more extreme), if the null hypothesis is true."
      ],
      "metadata": {
        "id": "RZCua94ImJYh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.  What are Type 1 and Type 2 errors in hypothesis testing\n",
        " Ans -  1. Type I Error (Œ±):\n",
        "Occurs when you reject the null hypothesis (H‚ÇÄ) even though it is actually true.\n",
        " * You think there is an effect, but there isn‚Äôt.\n",
        " * This is also called a false positive.\n",
        " * The probability of making a Type I error is the significance level (Œ±).\n",
        "        2.  2. Type II Error (Œ≤):\n",
        "Occurs when you fail to reject the null hypothesis, even though it is actually false.\n",
        " * You miss a real effect that actually exists.\n",
        " * This is also called a false negative.\n",
        " * The probability of making a Type II error is Œ≤"
      ],
      "metadata": {
        "id": "eHAr2SK-mZ5Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.  What is the difference between a one-tailed and a two-tailed test in hypothesis testing\n",
        "Ans -  1. One-Tailed Test (Directional Test)\n",
        "A one-tailed test checks for an effect in only one direction ‚Äî either greater than or less than a specific value.\n",
        " Theory:\n",
        "        You use a one-tailed test when your alternative hypothesis (H‚ÇÅ) is directional.\n",
        "        It focuses all the rejection region (Œ±) on one side of the distribution.\n",
        "        2. Two-Tailed Test (Non-directional Test)\n",
        "A two-tailed test checks for an effect in both directions ‚Äî the value can be either higher or lower than expected.\n",
        " Theory:\n",
        "        Used when the alternative hypothesis (H‚ÇÅ) is non-directional.\n",
        "        The rejection region is split equally between both tails of the sampling distribution."
      ],
      "metadata": {
        "id": "Icf3CE8qnDhw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.  What is the Z-test, and when is it used in hypothesis testing\n",
        "Ans - The Z-test is a statistical test used to determine whether there is a significant difference between a sample statistic and a population parameter (like the mean or proportion), under the assumption that the data follows a normal distribution.\n",
        " Z-test is used if the following conditions are met:\n",
        "\n",
        "* The population standard deviation (œÉ) is known\n",
        "\n",
        "* The sample size is large (typically n ‚â• 30) or the population is normally distributed\n",
        "\n",
        "* The data is randomly selected and independent\n",
        "\n",
        "* You are testing means or proportions"
      ],
      "metadata": {
        "id": "FMw-oxFInrUG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.  How do you calculate the Z-score, and what does it represent in hypothesis testing\n",
        "Ans - A Z-score is a standardized score that indicates how many standard deviations a data point or sample statistic is from the population mean.\n",
        "In hypothesis testing, the Z-score is used to determine whether to reject the null hypothesis by comparing it to critical values from the standard normal distribution (Z-distribution).\n",
        "The Z-score quantifies how far your sample result is from the population mean in units of standard deviation. In hypothesis testing, it is crucial for deciding whether a result is statistically significant based on the rejection region of the Z-distribution\n",
        "\n"
      ],
      "metadata": {
        "id": "H1AsYulfoJiW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.  What is the T-distribution, and when should it be used instead of the normal distribution\n",
        "Ans - The T-distribution (also called Student‚Äôs t-distribution) is a probability distribution similar to the normal distribution, but with heavier tails. This means it gives more probability to values far from the mean.\n",
        "* It is bell-shaped and symmetric, like the normal distribution.\n",
        "* The shape depends on the degrees of freedom (df) ‚Äî as df increases, the t-distribution approaches the normal distribution.\n",
        "\n",
        "The t-distribution is used instead of the normal distribution when dealing with small samples and unknown population standard deviation. It accounts for extra uncertainty and ensures more accurate inference in these cases. As the sample size grows, the t-distribution becomes almost identical to the normal distribution."
      ],
      "metadata": {
        "id": "n6XTWv36oqjm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.  What is the difference between a Z-test and a T-test\n",
        "Ans - 1. Z-test:\n",
        "The Z-test is based on the standard normal distribution (Z-distribution), which assumes the population variance (or standard deviation) is known.\n",
        "* It is used primarily when the sample size is large (typically ùëõ‚â•30n‚â•30), allowing the sampling distribution of the sample mean to be approximated as normal by the Central Limit Theorem.\n",
        "* The test statistic follows a normal distribution with mean zero and variance one.\n",
        "2. T-test:\n",
        "The T-test is based on the Student's t-distribution, which accounts for additional uncertainty due to the population variance being unknown.\n",
        "* It is used mainly when the sample size is small (typically ùëõ<30n<30) and the population variance must be estimated from the sample.\n",
        "* The test statistic follows a t-distribution, which is similar to the normal distribution but with heavier tails to reflect the increased uncertainty."
      ],
      "metadata": {
        "id": "eTeKaMMepGO8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12.  What is the T-test, and how is it used in hypothesis testing\n",
        "Ans - The T-test is a statistical test used to determine whether there is a significant difference between:\n",
        "* A sample mean and a known or hypothesized population mean, or\n",
        "* The means of two groups (independent or paired samples).\n",
        "     The T-test is used when the population standard deviation is unknown and sample sizes are small.\n",
        "\n"
      ],
      "metadata": {
        "id": "toFOS-rvqSyJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13.  What is the relationship between Z-test and T-test in hypothesis testing\n",
        "Ans - * Z-test assumes the population variance (œÉ¬≤) is known, and the test statistic follows a standard normal distribution (Z-distribution).\n",
        "\n",
        "      * T-test assumes the population variance is unknown and must be estimated from the sample. Because of this estimation, the test statistic follows a Student‚Äôs t-distribution, which has heavier tails to account for additional uncertainty."
      ],
      "metadata": {
        "id": "syo5EpbSq8Ld"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14.  What is a confidence interval, and how is it used to interpret statistical results\n",
        "Ans - A confidence interval is a range of values, derived from sample data, that is likely to contain the true population parameter (like the population mean) with a certain level of confidence.\n"
      ],
      "metadata": {
        "id": "Ge94al95up3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15.  What is the margin of error, and how does it affect the confidence interval\n",
        "Ans - The margin of error is the maximum amount by which the sample estimate is expected to differ from the true population parameter due to random sampling variability.\n",
        "* It represents the radius (or half-width) of a confidence interval.\n",
        "* It quantifies the uncertainty or precision of the estimate.\n",
        "* A larger margin of error means a wider confidence interval, indicating less precision.\n",
        "* A smaller margin of error means a narrower confidence interval, indicating more precision.\n",
        "\n"
      ],
      "metadata": {
        "id": "WrRt2HrZvFxG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16.  How is Bayes' Theorem used in statistics, and what is its significance\n",
        "Ans - Bayes‚Äô Theorem is a fundamental rule in probability theory that describes how to update the probability of a hypothesis based on new evidence.\n",
        "* Updating Beliefs with Data:\n",
        "       Bayes‚Äô Theorem is used to update prior beliefs (prior probabilities) about parameters or hypotheses when new data or evidence becomes available, producing a posterior distribution.\n",
        "* Bayesian Inference:\n",
        "      In Bayesian statistics, it is the core principle for making probabilistic inferences about unknown parameters by combining prior knowledge and observed data.\n",
        "* Decision Making:\n",
        "      It helps in decision-making processes where probabilities must be revised dynamically as more information arrives."
      ],
      "metadata": {
        "id": "w8EYU59xvkJe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17.  What is the Chi-square distribution, and when is it used\n",
        "Ans- The Chi-square distribution is a continuous probability distribution that arises from the sum of the squares of ùëò independent standard normal random variables.\n",
        "* Goodness-of-Fit Tests:\n",
        "      To check if an observed frequency distribution fits an expected distribution.\n",
        "Example: Testing if dice rolls follow a uniform distribution.\n",
        "* Test of Independence:\n",
        "      To determine whether two categorical variables are independent in a contingency table.\n",
        "Example: Checking if gender is independent of voting preference.\n",
        "* Test for Homogeneity:\n",
        "      To compare frequency distributions of a categorical variable across different populations.\n"
      ],
      "metadata": {
        "id": "WyF2T0OJwCTg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18.  What is the Chi-square goodness of fit test, and how is it applied\n",
        "Ans - The Chi-square goodness of fit test is a statistical test used to determine whether a set of observed frequencies matches an expected distribution. It helps evaluate whether a sample comes from a population with a specific distribution.\n",
        "Steps to Apply the Chi-square Goodness of Fit Test:\n",
        "* Collect Data:\n",
        "  Count the observed frequencies (O‚ÇÅ, O‚ÇÇ, ..., O‚Çñ) for each category.\n",
        "  Determine the expected frequencies (E‚ÇÅ, E‚ÇÇ, ..., E‚Çñ) based on the hypothesized distribution.\n",
        "* Check Assumptions:\n",
        "The data should be categorical.\n",
        "Expected frequency in each category should be at least 5 for the approximation to be valid."
      ],
      "metadata": {
        "id": "ms-W7R8RxHuK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YuHKIyLbz9-k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19.  What is the F-distribution, and when is it used in hypothesis testing\n",
        "Ans - The F-distribution is a continuous probability distribution that arises when comparing two variances. It is defined as the ratio of two independent chi-square distributions divided by their respective degrees of freedom.\n",
        " The F-distribution Used :\n",
        " * To Compare Two Variances (Variance Ratio Test):\n",
        "Used to test if two populations have equal variances.\n",
        "Null hypothesis (H‚ÇÄ):\n",
        " * Analysis of Variance (ANOVA):\n",
        "The most common application.\n",
        "Used to test whether three or more group means are significantly different.\n",
        "Null hypothesis (H‚ÇÄ): All group means are equal.\n",
        "\n"
      ],
      "metadata": {
        "id": "oS0cZx30z-8-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20.  What is an ANOVA test, and what are its assumptions\n",
        "Ans - ANOVA (Analysis of Variance) is a statistical test used to determine whether there are statistically significant differences between the means of three or more independent groups.\n",
        "It helps assess whether observed differences in sample means reflect real differences in the population or are due to random variation.\n",
        "  Assumptions of ANOVA:\n",
        "Independence of Observations:\n",
        "* Each sample must be collected independently from the others.\n",
        "* Normality:\n",
        "The distribution of the residuals (errors) in each group should be approximately normal.\n",
        "* Homogeneity of Variances (Homoscedasticity):\n",
        "The variances among the groups should be approximately equal.\n",
        "\n"
      ],
      "metadata": {
        "id": "OEq0lWr000O9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21.  What are the different types of ANOVA tests\n",
        "Ans -  Types of ANOVA:\n",
        "* One-way ANOVA ‚Äì One independent variable with 3 or more groups.\n",
        "* Two-way ANOVA ‚Äì Two independent variables (factors).\n",
        "* Repeated Measures ANOVA ‚Äì Used when the same subjects are tested under different conditions or over time."
      ],
      "metadata": {
        "id": "uDbXk9xn1aJe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22.  What is the F-test, and how does it relate to hypothesis testing?\n",
        "Ans - The F-test is a statistical test that uses the F-distribution to compare two variances or assess overall model significance. It is commonly used in hypothesis testing to determine whether the variability between group means is greater than would be expected by chance.\n",
        "* The F-test is a statistical method used to compare variances or group means.\n",
        "* It is widely used in ANOVA, regression analysis, and variance comparison.\n",
        "* A significant F-test result suggests that the observed differences or relationships are unlikely due to chance."
      ],
      "metadata": {
        "id": "ubLCi7op1tgm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  PRACTICAL  PART 1"
      ],
      "metadata": {
        "id": "FpRA7VHDnhvJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Write a Python program to generate a random variable and display its value\n"
      ],
      "metadata": {
        "id": "Zz6HTk1Unqbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random_variable = random.randint(1, 100)\n",
        "\n",
        "print(\"The generated random variable is:\", random_variable)\n"
      ],
      "metadata": {
        "id": "JrR6-3won-mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Generate a discrete uniform distribution using Python and plot the probability mass function (PMF)\n"
      ],
      "metadata": {
        "id": "z_Px20fWoSr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import randint\n",
        "\n",
        "low = 1\n",
        "high = 7\n",
        "\n",
        "data = randint.rvs(low, high, size=1000)\n",
        "\n",
        "x = np.arange(low, high)\n",
        "\n",
        "pmf_values = randint.pmf(x, low, high)\n",
        "\n",
        "plt.stem(x, pmf_values, use_line_collection=True)\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Probability')\n",
        "plt.title('PMF of Discrete Uniform Distribution')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "a1NOy_TfoWDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Write a Python function to calculate the probability distribution function (PDF) of a Bernoulli distribution\n"
      ],
      "metadata": {
        "id": "RdLaCBGooy8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bernoulli_pdf(x, p):\n",
        "    \"\"\"\n",
        "    Calculate the PDF (PMF) of a Bernoulli distribution.\n",
        "\n",
        "    Parameters:\n",
        "    x (int): The value (0 or 1)\n",
        "    p (float): Probability of success (0 ‚â§ p ‚â§ 1)\n",
        "\n",
        "    Returns:\n",
        "    float: Probability P(X = x)\n",
        "    \"\"\"\n",
        "    if x not in [0, 1]:\n",
        "        return 0.0\n",
        "    return p**x * (1 - p)**(1 - x)\n",
        "\n",
        "p = 0.7\n",
        "print(\"P(X=0):\", bernoulli_pdf(0, p))\n",
        "print(\"P(X=1):\", bernoulli_pdf(1, p))\n"
      ],
      "metadata": {
        "id": "mnUz2I4io15R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Write a Python script to simulate a binomial distribution with n=10 and p=0.5, then plot its histogram\n"
      ],
      "metadata": {
        "id": "d4DsSFsjpHs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 10\n",
        "p = 0.5\n",
        "size = 1000\n",
        "\n",
        "data = np.random.binomial(n, p, size)\n",
        "\n",
        "plt.hist(data, bins=np.arange(0, n+2) - 0.5, density=True, edgecolor='black', alpha=0.7)\n",
        "plt.title('Binomial Distribution Histogram (n=10, p=0.5)')\n",
        "plt.xlabel('Number of Successes')\n",
        "plt.ylabel('Probability')\n",
        "plt.grid(True)\n",
        "plt.xticks(range(n+1))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Y-J538bupMcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Create a Poisson distribution and visualize it using Python\n"
      ],
      "metadata": {
        "id": "jHFNnjFjpiP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import poisson\n",
        "\n",
        "mu = 4\n",
        "\n",
        "pmf_values = poisson.pmf(x, mu)\n",
        "\n",
        "plt.stem(x, pmf_values, basefmt=\" \", use_line_collection=True)\n",
        "plt.title('Poisson Distribution (Œª = 4)')\n",
        "plt.xlabel('Number of Events (x)')\n",
        "plt.ylabel('Probability P(X = x)')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "v3JxblrAplwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Write a Python program to calculate and plot the cumulative distribution function (CDF) of a discrete uniform distribution"
      ],
      "metadata": {
        "id": "xWDALbU3p4n2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import randint\n",
        "\n",
        "low = 1\n",
        "high = 7\n",
        "\n",
        "x = np.arange(low - 1, high + 1)\n",
        "\n",
        "cdf_values = randint.cdf(x, low, high)\n",
        "\n",
        "plt.step(x, cdf_values, where='post', label='CDF')\n",
        "plt.title('CDF of Discrete Uniform Distribution (1 to 6)')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('Cumulative Probability')\n",
        "plt.grid(True)\n",
        "plt.xticks(range(low - 1, high + 1))\n",
        "plt.yticks(np.linspace(0, 1, high - low + 2))\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "z9BG6z3qp-DQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.  Generate a continuous uniform distribution using NumPy and visualize it\n"
      ],
      "metadata": {
        "id": "Kkkkrk90qN-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "low = 0.0\n",
        "high = 10.0\n",
        "size = 1000\n",
        "\n",
        "data = np.random.uniform(low, high, size)\n",
        "\n",
        "plt.hist(data, bins=30, density=True, alpha=0.6, color='skyblue', edgecolor='black', label='Sampled Data')\n",
        "\n",
        "x = np.linspace(low, high, 1000)\n",
        "pdf = [1 / (high - low)] * len(x)\n",
        "\n",
        "plt.plot(x, pdf, 'r--', label='Theoretical PDF')\n",
        "\n",
        "plt.title('Continuous Uniform Distribution (U[0, 10])')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Density')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1nq7uLRpqSCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Simulate data from a normal distribution and plot its histogram\n"
      ],
      "metadata": {
        "id": "4VdRHN21qj5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mean = 0\n",
        "std_dev = 1\n",
        "size = 1000\n",
        "\n",
        "data = np.random.normal(mean, std_dev, size)\n",
        "\n",
        "plt.hist(data, bins=30, density=True, alpha=0.6, color='lightgreen', edgecolor='black', label='Sampled Data')\n",
        "\n",
        "x = np.linspace(mean - 4*std_dev, mean + 4*std_dev, 1000)\n",
        "pdf = (1 / (std_dev * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mean) / std_dev)**2)\n",
        "plt.plot(x, pdf, 'r--', label='Theoretical PDF')\n",
        "\n",
        "plt.title('Normal Distribution Histogram (Œº = 0, œÉ = 1)')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Density')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Uey-qReiqoVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Write a Python function to calculate Z-scores from a dataset and plot them\n"
      ],
      "metadata": {
        "id": "kqTzxyRzq9YT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def calculate_and_plot_z_scores(data):\n",
        "    \"\"\"\n",
        "    Calculates Z-scores from the dataset and plots them.\n",
        "\n",
        "    Parameters:\n",
        "    data (array-like): Input dataset\n",
        "    \"\"\"\n",
        "    data = np.array(data)\n",
        "    mean = np.mean(data)\n",
        "    std_dev = np.std(data)\n",
        "\n",
        "    z_scores = (data - mean) / std_dev\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.scatter(range(len(data)), z_scores, color='purple', alpha=0.7)\n",
        "    plt.axhline(0, color='black', linestyle='--', label='Mean (Z = 0)')\n",
        "    plt.axhline(1, color='green', linestyle='--', label='Z = +1')\n",
        "    plt.axhline(-1, color='red', linestyle='--', label='Z = -1')\n",
        "    plt.title('Z-scores of Dataset')\n",
        "    plt.xlabel('Data Index')\n",
        "    plt.ylabel('Z-score')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    return z_scores\n",
        "\n"
      ],
      "metadata": {
        "id": "UcHNzJnerBzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Implement the Central Limit Theorem (CLT) using Python for a non-normal distribution.\n"
      ],
      "metadata": {
        "id": "0H0do27srSZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "population_size = 100000\n",
        "sample_size = 30\n",
        "num_samples = 1000\n",
        "\n",
        "population = np.random.exponential(scale=2.0, size=population_size)\n",
        "\n",
        "sample_means = []\n",
        "for _ in range(num_samples):\n",
        "    sample = np.random.choice(population, size=sample_size, replace=False)\n",
        "    sample_means.append(np.mean(sample))\n",
        "sample_means = np.array(sample_means)\n",
        "\n",
        "plt.hist(sample_means, bins=30, density=True, alpha=0.6, color='skyblue', edgecolor='black', label='Sample Means')\n",
        "\n",
        "mean_of_means = np.mean(sample_means)\n",
        "std_of_means = np.std(sample_means)\n",
        "x = np.linspace(min(sample_means), max(sample_means), 1000)\n",
        "plt.plot(x, norm.pdf(x, mean_of_means, std_of_means), 'r--', label='Normal Approximation')\n",
        "\n",
        "plt.title('Central Limit Theorem Demonstration\\nSample Size = {}'.format(sample_size))\n",
        "plt.xlabel('Sample Mean')\n",
        "plt.ylabel('Density')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "XXH0V36erV_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.Simulate multiple samples from a normal distribution and verify the Central Limit Theorem\n"
      ],
      "metadata": {
        "id": "Xq3tLAWwrnPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "population_mean = 5\n",
        "population_std = 2\n",
        "sample_size = 30\n",
        "num_samples = 1000\n",
        "\n",
        "population = np.random.normal(population_mean, population_std, 100000)\n",
        "\n",
        "sample_means = []\n",
        "for _ in range(num_samples):\n",
        "    sample = np.random.choice(population, sample_size, replace=False)\n",
        "    sample_means.append(np.mean(sample))\n",
        "sample_means = np.array(sample_means)\n",
        "\n",
        "plt.hist(sample_means, bins=30, density=True, alpha=0.6, color='lightcoral', edgecolor='black', label='Sample Means')\n",
        "\n",
        "mean_of_means = population_mean\n",
        "std_of_means = population_std / np.sqrt(sample_size)\n",
        "x = np.linspace(min(sample_means), max(sample_means), 1000)\n",
        "plt.plot(x, norm.pdf(x, mean_of_means, std_of_means), 'b--', label='Theoretical Normal PDF')\n",
        "\n",
        "plt.title('CLT Verification with Normal Population\\nSample Size = {}'.format(sample_size))\n",
        "plt.xlabel('Sample Mean')\n",
        "plt.ylabel('Density')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uNXEKcZsrqyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Write a Python function to calculate and plot the standard normal distribution (mean = 0, std = 1)\n"
      ],
      "metadata": {
        "id": "OBM_cNQ3r2UB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "def plot_standard_normal():\n",
        "    \"\"\"\n",
        "    Calculate and plot the standard normal distribution PDF (mean=0, std=1).\n",
        "    \"\"\"\n",
        "    x = np.linspace(-4, 4, 1000)\n",
        "\n",
        "    pdf = norm.pdf(x, loc=0, scale=1)\n",
        "\n",
        "    plt.plot(x, pdf, 'b-', label='Standard Normal PDF (Œº=0, œÉ=1)')\n",
        "    plt.title('Standard Normal Distribution')\n",
        "    plt.xlabel('x')\n",
        "    plt.ylabel('Probability Density')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "lvYwAl1qr6Ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. Generate random variables and calculate their corresponding probabilities using the binomial distribution\n"
      ],
      "metadata": {
        "id": "0DY1y0YNsDuh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import binom\n",
        "\n",
        "n = 10\n",
        "p = 0.5\n",
        "\n",
        "x = np.arange(0, n+1)\n",
        "\n",
        "pmf_values = binom.pmf(x, n, p)\n",
        "\n",
        "print(\"Number of successes (x):\", x)\n",
        "print(\"Corresponding probabilities (PMF):\", pmf_values)\n",
        "\n"
      ],
      "metadata": {
        "id": "NxsocUKYsG-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. Write a Python program to calculate the Z-score for a given data point and compare it to a standard normal distribution"
      ],
      "metadata": {
        "id": "5Ta1xn_IsUGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "def calculate_z_score(x, data):\n",
        "    \"\"\"\n",
        "    Calculate Z-score for a data point x given the dataset.\n",
        "\n",
        "    Parameters:\n",
        "    - x: the data point (float)\n",
        "    - data: list or numpy array of data points\n",
        "\n",
        "    Returns:\n",
        "    - z_score: the Z-score of x\n",
        "    \"\"\"\n",
        "    mean = np.mean(data)\n",
        "    std = np.std(data)\n",
        "    z_score = (x - mean) / std\n",
        "    return z_score\n",
        "\n",
        "def plot_standard_normal_with_z(z):\n",
        "    \"\"\"\n",
        "    Plot the standard normal distribution and mark the Z-score.\n",
        "\n",
        "    Parameters:\n",
        "    - z: Z-score (float)\n",
        "    \"\"\"\n",
        "    x = np.linspace(-4, 4, 1000)\n",
        "    pdf = norm.pdf(x)\n",
        "\n",
        "    plt.plot(x, pdf, label='Standard Normal PDF')\n",
        "    plt.fill_between(x, 0, pdf, alpha=0.2)\n",
        "\n",
        "    plt.axvline(z, color='red', linestyle='--', label=f'Z = {z:.2f}')\n",
        "    plt.scatter(z, norm.pdf(z), color='red')\n",
        "\n",
        "    plt.title('Standard Normal Distribution with Z-score')\n",
        "    plt.xlabel('Z')\n",
        "    plt.ylabel('Probability Density')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "OAigX7ScsZH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. Implement hypothesis testing using Z-statistics for a sample dataset\n"
      ],
      "metadata": {
        "id": "hAda9KyzskrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "def z_test(sample, pop_mean, pop_std, alpha=0.05, alternative='two-sided'):\n",
        "    \"\"\"\n",
        "    Perform a one-sample Z-test.\n",
        "\n",
        "    Parameters:\n",
        "    - sample: array-like, sample data\n",
        "    - pop_mean: float, hypothesized population mean\n",
        "    - pop_std: float, known population standard deviation\n",
        "    - alpha: significance level (default 0.05)\n",
        "    - alternative: 'two-sided', 'greater', or 'less'\n",
        "\n",
        "    Returns:\n",
        "    - z_stat: computed Z statistic\n",
        "    - p_value: p-value of the test\n",
        "    - conclusion: reject or fail to reject the null hypothesis\n",
        "    \"\"\"\n",
        "\n",
        "    n = len(sample)\n",
        "    sample_mean = np.mean(sample)\n",
        "\n",
        "    z_stat = (sample_mean - pop_mean) / (pop_std / np.sqrt(n))\n",
        "\n",
        "    if alternative == 'two-sided':\n",
        "        p_value = 2 * (1 - norm.cdf(abs(z_stat)))\n",
        "    elif alternative == 'greater':\n",
        "        p_value = 1 - norm.cdf(z_stat)\n",
        "    elif alternative == 'less':\n",
        "        p_value = norm.cdf(z_stat)\n",
        "    else:\n",
        "        raise ValueError(\"alternative must be 'two-sided', 'greater', or 'less'\")\n",
        "\n",
        "    if p_value < alpha:\n",
        "        conclusion = \"Reject the null hypothesis\"\n",
        "    else:\n",
        "        conclusion = \"Fail to reject the null hypothesis\"\n",
        "\n",
        "    return z_stat, p_value, conclusion\n",
        "\n",
        "\n",
        "print(f\"Z-statistic: {z_stat:.3f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "print(f\"Conclusion: {conclusion}\")\n"
      ],
      "metadata": {
        "id": "CjzV_tYdssT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. Create a confidence interval for a dataset using Python and interpret the result\n"
      ],
      "metadata": {
        "id": "GyGb6aaIs850"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def confidence_interval(data, confidence=0.95):\n",
        "    \"\"\"\n",
        "    Calculate the confidence interval for the mean of the data.\n",
        "\n",
        "    Parameters:\n",
        "    - data: array-like, the dataset\n",
        "    - confidence: float, confidence level (default 0.95)\n",
        "\n",
        "    Returns:\n",
        "    - (lower_bound, upper_bound): tuple representing the confidence interval\n",
        "    \"\"\"\n",
        "    data = np.array(data)\n",
        "    n = len(data)\n",
        "    mean = np.mean(data)\n",
        "    std_err = stats.sem(data)\n",
        "\n",
        "    t_crit = stats.t.ppf((1 + confidence) / 2, df=n-1)\n",
        "\n",
        "    margin_of_error = t_crit * std_err\n",
        "\n",
        "    lower_bound = mean - margin_of_error\n",
        "    upper_bound = mean + margin_of_error\n",
        "\n",
        "    return lower_bound, upper_bound\n",
        "\n"
      ],
      "metadata": {
        "id": "YQe6T1GltAhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. Generate data from a normal distribution, then calculate and interpret the confidence interval for its mean\n"
      ],
      "metadata": {
        "id": "WTbnjZiwtON-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "np.random.seed(42)\n",
        "mean_true = 100\n",
        "std_true = 15\n",
        "sample_size = 50\n",
        "\n",
        "data = np.random.normal(loc=mean_true, scale=std_true, size=sample_size)\n",
        "\n",
        "def confidence_interval(data, confidence=0.95):\n",
        "    data = np.array(data)\n",
        "    n = len(data)\n",
        "    mean = np.mean(data)\n",
        "    std_err = stats.sem(data)\n",
        "    t_crit = stats.t.ppf((1 + confidence) / 2, df=n-1)\n",
        "    margin_of_error = t_crit * std_err\n",
        "    lower_bound = mean - margin_of_error\n",
        "    upper_bound = mean + margin_of_error\n",
        "    return mean, lower_bound, upper_bound\n",
        "\n",
        "mean_sample, lower, upper = confidence_interval(data)\n",
        "\n",
        "print(f\"Sample mean: {mean_sample:.2f}\")\n",
        "print(f\"95% Confidence Interval: ({lower:.2f}, {upper:.2f})\")\n",
        "print(\"\\nInterpretation:\")\n",
        "print(f\"We are 95% confident that the true population mean lies between {lower:.2f} and {upper:.2f}.\")\n"
      ],
      "metadata": {
        "id": "BRw0q-tbtRu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. Write a Python script to calculate and visualize the probability density function (PDF) of a normal distribution\n"
      ],
      "metadata": {
        "id": "85cbZxiqtcsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "def plot_normal_pdf(mean=0, std=1, x_range=(-5, 5)):\n",
        "    \"\"\"\n",
        "    Calculate and plot the PDF of a normal distribution.\n",
        "\n",
        "    Parameters:\n",
        "    - mean: Mean of the normal distribution (default 0)\n",
        "    - std: Standard deviation of the normal distribution (default 1)\n",
        "    - x_range: Tuple with (min, max) range for x values (default (-5, 5))\n",
        "    \"\"\"\n",
        "    x = np.linspace(x_range[0], x_range[1], 1000)\n",
        "    pdf_values = norm.pdf(x, loc=mean, scale=std)\n",
        "\n",
        "    plt.plot(x, pdf_values, 'b-', label=f'Normal PDF\\nŒº={mean}, œÉ={std}')\n",
        "    plt.title('Probability Density Function (PDF) of Normal Distribution')\n",
        "    plt.xlabel('x')\n",
        "    plt.ylabel('Density')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "oxQPKXuBtf6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. Use Python to calculate and interpret the cumulative distribution function (CDF) of a Poisson distribution\n"
      ],
      "metadata": {
        "id": "DW7pj48St-cZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import poisson\n",
        "\n",
        "lambda_ = 4\n",
        "\n",
        "x_values = np.arange(0, 11)\n",
        "\n",
        "cdf_values = poisson.cdf(x_values, mu=lambda_)\n",
        "\n",
        "for x, cdf_val in zip(x_values, cdf_values):\n",
        "    print(f\"P(X ‚â§ {x}) = {cdf_val:.4f}\")\n",
        "\n",
        "k = 6\n",
        "prob_up_to_k = poisson.cdf(k, mu=lambda_)\n",
        "print(f\"\\nInterpretation:\")\n",
        "print(f\"The probability of observing {k} or fewer events (X ‚â§ {k}) when the average rate is {lambda_} is approximately {prob_up_to_k:.4f}.\")\n"
      ],
      "metadata": {
        "id": "wkP-c8EmuBPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. Simulate a random variable using a continuous uniform distribution and calculate its expected value\n"
      ],
      "metadata": {
        "id": "6F_O7kzruUua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "a = 2\n",
        "b = 10\n",
        "\n",
        "np.random.seed(42)\n",
        "sample_size = 10000\n",
        "samples = np.random.uniform(low=a, high=b, size=sample_size)\n",
        "\n",
        "expected_value = (a + b) / 2\n",
        "\n",
        "sample_mean = np.mean(samples)\n",
        "\n",
        "print(f\"Theoretical Expected Value (mean) of Uniform({a}, {b}): {expected_value:.2f}\")\n",
        "print(f\"Sample Mean from simulation: {sample_mean:.2f}\")\n"
      ],
      "metadata": {
        "id": "khyZ8OmQuYVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. Write a Python program to compare the standard deviations of two datasets and visualize the difference\n"
      ],
      "metadata": {
        "id": "MkJpi-lAuxqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)\n",
        "data1 = np.random.normal(loc=50, scale=5, size=500)\n",
        "data2 = np.random.normal(loc=50, scale=10, size=500)\n",
        "\n",
        "std1 = np.std(data1, ddof=1)\n",
        "std2 = np.std(data2, ddof=1)\n",
        "\n",
        "print(f\"Standard deviation of Dataset 1: {std1:.2f}\")\n",
        "print(f\"Standard deviation of Dataset 2: {std2:.2f}\")\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(data1, bins=30, color='skyblue', edgecolor='black')\n",
        "plt.title(f'Dataset 1 (std dev ‚âà {std1:.2f})')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(data2, bins=30, color='salmon', edgecolor='black')\n",
        "plt.title(f'Dataset 2 (std dev ‚âà {std2:.2f})')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.suptitle('Comparison of Standard Deviations')\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WQNphC_iu0G_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. Calculate the range and interquartile range (IQR) of a dataset generated from a normal distribution\n"
      ],
      "metadata": {
        "id": "hBivex66vBim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)\n",
        "data = np.random.normal(loc=50, scale=10, size=1000)\n",
        "\n",
        "data_range = np.max(data) - np.min(data)\n",
        "\n",
        "q75, q25 = np.percentile(data, [75, 25])\n",
        "iqr = q75 - q25\n",
        "\n",
        "print(f\"Range of the dataset: {data_range:.2f}\")\n",
        "print(f\"Interquartile Range (IQR) of the dataset: {iqr:.2f}\")\n"
      ],
      "metadata": {
        "id": "TqkKgNJ6vEDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. Implement Z-score normalization on a dataset and visualize its transformation\n"
      ],
      "metadata": {
        "id": "F7TjjAymvPkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "np.random.seed(42)\n",
        "data = np.random.normal(loc=50, scale=10, size=500)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "data_normalized = scaler.fit_transform(data.reshape(-1, 1)).flatten()\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(data, bins=30, color='skyblue', edgecolor='black')\n",
        "plt.title('Original Data')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(data_normalized, bins=30, color='salmon', edgecolor='black')\n",
        "plt.title('Z-score Normalized Data')\n",
        "plt.xlabel('Z-score')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.suptitle('Comparison Before and After Z-score Normalization')\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ah2APuEGvS13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. Write a Python function to calculate the skewness and kurtosis of a dataset generated from a normal distribution."
      ],
      "metadata": {
        "id": "lvWrzdEJvaqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "def calculate_skewness_kurtosis(data):\n",
        "    \"\"\"\n",
        "    Calculate skewness and kurtosis of a dataset.\n",
        "\n",
        "    Parameters:\n",
        "    - data: array-like, the dataset\n",
        "\n",
        "    Returns:\n",
        "    - skewness: measure of asymmetry\n",
        "    - kurtosis_val: measure of tail heaviness (excess kurtosis)\n",
        "    \"\"\"\n",
        "    skewness = skew(data)\n",
        "    kurtosis_val = kurtosis(data)\n",
        "    return skewness, kurtosis_val\n",
        "\n",
        "\n",
        "print(f\"Skewness: {skewness:.4f}\")\n",
        "print(f\"Kurtosis (excess): {kurtosis_val:.4f}\")\n"
      ],
      "metadata": {
        "id": "iz1HE6ZAvfuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "      PRACTICAL 2"
      ],
      "metadata": {
        "id": "yar_hTb_vqy8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Write a Python program to perform a Z-test for comparing a sample mean to a known population mean and interpret the results"
      ],
      "metadata": {
        "id": "C1xp2D3SvwYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "def one_sample_z_test(sample, pop_mean, pop_std, alpha=0.05, alternative='two-sided'):\n",
        "    \"\"\"\n",
        "    Perform a one-sample Z-test.\n",
        "\n",
        "    Parameters:\n",
        "    - sample: array-like, sample data\n",
        "    - pop_mean: float, known population mean (null hypothesis value)\n",
        "    - pop_std: float, known population standard deviation\n",
        "    - alpha: significance level (default 0.05)\n",
        "    - alternative: 'two-sided', 'greater', or 'less' for the alternative hypothesis\n",
        "\n",
        "    Returns:\n",
        "    - z_stat: computed z statistic\n",
        "    - p_value: p-value for the test\n",
        "    - conclusion: interpretation string\n",
        "    \"\"\"\n",
        "    n = len(sample)\n",
        "    sample_mean = np.mean(sample)\n",
        "\n",
        "    z_stat = (sample_mean - pop_mean) / (pop_std / np.sqrt(n))\n",
        "\n",
        "    if alternative == 'two-sided':\n",
        "        p_value = 2 * (1 - norm.cdf(abs(z_stat)))\n",
        "    elif alternative == 'greater':\n",
        "        p_value = 1 - norm.cdf(z_stat)\n",
        "    elif alternative == 'less':\n",
        "        p_value = norm.cdf(z_stat)\n",
        "    else:\n",
        "        raise ValueError(\"alternative must be 'two-sided', 'greater', or 'less'\")\n",
        "\n",
        "    if p_value < alpha:\n",
        "        conclusion = \"Reject the null hypothesis: sample mean is significantly different.\"\n",
        "    else:\n",
        "        conclusion = \"Fail to reject the null hypothesis: no significant difference detected.\"\n",
        "\n",
        "    return z_stat, p_value, conclusion\n",
        "\n",
        "\n",
        "print(f\"Z-statistic: {z_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "print(f\"Conclusion: {conclusion}\")\n"
      ],
      "metadata": {
        "id": "cZFTHAUFv30A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Simulate random data to perform hypothesis testing and calculate the corresponding P-value using Python\n"
      ],
      "metadata": {
        "id": "UHeFKVJ_wFuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "np.random.seed(42)\n",
        "sample1 = np.random.normal(loc=50, scale=5, size=30)\n",
        "sample2 = np.random.normal(loc=52, scale=5, size=30)\n",
        "\n",
        "t_stat, p_value = ttest_ind(sample1, sample2)\n",
        "\n",
        "print(f\"T-statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject null hypothesis: The means are significantly different.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: No significant difference between means.\")\n"
      ],
      "metadata": {
        "id": "UInYYdDMwQH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Implement a one-sample Z-test using Python to compare the sample mean with the population mean\n"
      ],
      "metadata": {
        "id": "NBEHCrKdwWTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "def one_sample_z_test(sample, pop_mean, pop_std, alpha=0.05, alternative='two-sided'):\n",
        "    \"\"\"\n",
        "    Perform a one-sample Z-test.\n",
        "\n",
        "    Parameters:\n",
        "    - sample: array-like, sample data\n",
        "    - pop_mean: float, population mean under the null hypothesis\n",
        "    - pop_std: float, population standard deviation (known)\n",
        "    - alpha: significance level, default 0.05\n",
        "    - alternative: 'two-sided', 'greater', or 'less'\n",
        "\n",
        "    Returns:\n",
        "    - z_stat: calculated Z statistic\n",
        "    - p_value: p-value of the test\n",
        "    - result: conclusion string\n",
        "    \"\"\"\n",
        "    n = len(sample)\n",
        "    sample_mean = np.mean(sample)\n",
        "    std_error = pop_std / np.sqrt(n)\n",
        "    z_stat = (sample_mean - pop_mean) / std_error\n",
        "\n",
        "    if alternative == 'two-sided':\n",
        "        p_value = 2 * (1 - norm.cdf(abs(z_stat)))\n",
        "    elif alternative == 'greater':\n",
        "        p_value = 1 - norm.cdf(z_stat)\n",
        "    elif alternative == 'less':\n",
        "        p_value = norm.cdf(z_stat)\n",
        "    else:\n",
        "        raise ValueError(\"alternative must be 'two-sided', 'greater', or 'less'\")\n",
        "\n",
        "    if p_value < alpha:\n",
        "        result = f\"Reject the null hypothesis (p={p_value:.4f} < {alpha})\"\n",
        "    else:\n",
        "        result = f\"Fail to reject the null hypothesis (p={p_value:.4f} >= {alpha})\"\n",
        "\n",
        "    return z_stat, p_value, result\n",
        "\n",
        "\n",
        "print(f\"Z-statistic: {z_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "print(f\"Conclusion: {conclusion}\")\n"
      ],
      "metadata": {
        "id": "4bkOI-TlwZik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Perform a two-tailed Z-test using Python and visualize the decision region on a plot\n"
      ],
      "metadata": {
        "id": "Rb4ezHXXwlz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "def two_tailed_z_test(sample, pop_mean, pop_std, alpha=0.05):\n",
        "    n = len(sample)\n",
        "    sample_mean = np.mean(sample)\n",
        "    std_error = pop_std / np.sqrt(n)\n",
        "    z_stat = (sample_mean - pop_mean) / std_error\n",
        "\n",
        "    p_value = 2 * (1 - norm.cdf(abs(z_stat)))\n",
        "\n",
        "    z_crit = norm.ppf(1 - alpha / 2)\n",
        "\n",
        "    x = np.linspace(-4, 4, 1000)\n",
        "    y = norm.pdf(x)\n",
        "\n",
        "    plt.figure(figsize=(10,6))\n",
        "    plt.plot(x, y, label='Standard Normal Distribution')\n",
        "\n",
        "    plt.fill_between(x, 0, y, where=(x <= -z_crit), color='red', alpha=0.3, label='Rejection Region')\n",
        "    plt.fill_between(x, 0, y, where=(x >= z_crit), color='red', alpha=0.3)\n",
        "\n",
        "    plt.axvline(z_stat, color='blue', linestyle='--', linewidth=2, label=f'Observed Z = {z_stat:.2f}')\n",
        "\n",
        "    plt.title('Two-tailed Z-test Decision Regions')\n",
        "    plt.xlabel('Z value')\n",
        "    plt.ylabel('Probability Density')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    return z_stat, p_value, z_crit\n",
        "\n",
        "\n",
        "print(f\"Z-statistic: {z_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "print(f\"Critical Z-values: ¬±{z_crit:.4f}\")\n",
        "\n",
        "if abs(z_stat) > z_crit:\n",
        "    print(\"Reject the null hypothesis.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis.\")\n"
      ],
      "metadata": {
        "id": "ajiByKSawonZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Create a Python function that calculates and visualizes Type 1 and Type 2 errors during hypothesis testing\n"
      ],
      "metadata": {
        "id": "HRiZTXbcw26_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "def plot_type1_type2_errors(pop_mean, alt_mean, pop_std, n, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Visualize Type 1 and Type 2 errors for a one-sample Z-test.\n",
        "\n",
        "    Parameters:\n",
        "    - pop_mean: mean under null hypothesis\n",
        "    - alt_mean: mean under alternative hypothesis\n",
        "    - pop_std: population standard deviation\n",
        "    - n: sample size\n",
        "    - alpha: significance level (Type 1 error rate)\n",
        "    \"\"\"\n",
        "    std_error = pop_std / np.sqrt(n)\n",
        "\n",
        "    z_crit = norm.ppf(1 - alpha/2)\n",
        "\n",
        "    crit_low = pop_mean - z_crit * std_error\n",
        "    crit_high = pop_mean + z_crit * std_error\n",
        "\n",
        "    x_min = min(pop_mean, alt_mean) - 4 * std_error\n",
        "    x_max = max(pop_mean, alt_mean) + 4 * std_error\n",
        "    x = np.linspace(x_min, x_max, 1000)\n",
        "\n",
        "    null_pdf = norm.pdf(x, loc=pop_mean, scale=std_error)\n",
        "    alt_pdf = norm.pdf(x, loc=alt_mean, scale=std_error)\n",
        "\n",
        "    plt.figure(figsize=(12,6))\n",
        "\n",
        "    plt.plot(x, null_pdf, label='Null Hypothesis (H0)', color='blue')\n",
        "    plt.plot(x, alt_pdf, label='Alternative Hypothesis (H1)', color='green')\n",
        "\n",
        "    plt.fill_between(x, 0, null_pdf, where=(x < crit_low) | (x > crit_high),\n",
        "                     color='red', alpha=0.3, label='Type 1 Error (Œ±)')\n",
        "\n",
        "    plt.fill_between(x, 0, alt_pdf, where=(x >= crit_low) & (x <= crit_high),\n",
        "                     color='orange', alpha=0.3, label='Type 2 Error (Œ≤)')\n",
        "\n",
        "    plt.axvline(crit_low, color='red', linestyle='--', label='Critical Values')\n",
        "    plt.axvline(crit_high, color='red', linestyle='--')\n",
        "\n",
        "    plt.title('Type 1 and Type 2 Errors in Hypothesis Testing')\n",
        "    plt.xlabel('Sample Mean')\n",
        "    plt.ylabel('Probability Density')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    beta = norm.cdf(crit_high, loc=alt_mean, scale=std_error) - norm.cdf(crit_low, loc=alt_mean, scale=std_error)\n",
        "    power = 1 - beta\n",
        "\n",
        "    print(f\"Significance level (Type 1 error, Œ±): {alpha}\")\n",
        "    print(f\"Type 2 error (Œ≤): {beta:.4f}\")\n",
        "    print(f\"Power (1 - Œ≤): {power:.4f}\")\n"
      ],
      "metadata": {
        "id": "6dxWPbluw6ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Write a Python program to perform an independent T-test and interpret the results\n"
      ],
      "metadata": {
        "id": "xtclBABBxQrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "np.random.seed(42)\n",
        "group1 = np.random.normal(loc=100, scale=15, size=30)\n",
        "group2 = np.random.normal(loc=110, scale=15, size=30)\n",
        "\n",
        "t_stat, p_value = ttest_ind(group1, group2)\n",
        "\n",
        "print(f\"T-statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: The two groups have significantly different means.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant difference between the groups.\")\n"
      ],
      "metadata": {
        "id": "UjmNkBkExT7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Perform a paired sample T-test using Python and visualize the comparison results\n"
      ],
      "metadata": {
        "id": "9EXL4-I7xdvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import ttest_rel\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)\n",
        "before = np.random.normal(loc=75, scale=10, size=30)\n",
        "after = before + np.random.normal(loc=5, scale=8, size=30)\n",
        "\n",
        "t_stat, p_value = ttest_rel(before, after)\n",
        "\n",
        "print(f\"Paired T-test statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject null hypothesis: Significant difference between paired samples.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: No significant difference detected.\")\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "plt.boxplot([before, after], labels=['Before', 'After'], patch_artist=True,\n",
        "            boxprops=dict(facecolor='lightblue'))\n",
        "plt.title('Paired Sample Comparison')\n",
        "plt.ylabel('Values')\n",
        "\n",
        "for i in range(len(before)):\n",
        "    plt.plot([1, 2], [before[i], after[i]], marker='o', color='gray', alpha=0.5)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tbDbHBHjxhXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 8. Simulate data and perform both Z-test and T-test, then compare the results using Python\n"
      ],
      "metadata": {
        "id": "KmxiNI1jyVmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm, t, ttest_1samp\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "pop_mean = 100\n",
        "pop_std = 15\n",
        "sample_size = 30\n",
        "alpha = 0.05\n",
        "\n",
        "sample = np.random.normal(loc=105, scale=pop_std, size=sample_size)\n",
        "\n",
        "sample_mean = np.mean(sample)\n",
        "sample_std = np.std(sample, ddof=1)\n",
        "\n",
        "std_error_z = pop_std / np.sqrt(sample_size)\n",
        "z_stat = (sample_mean - pop_mean) / std_error_z\n",
        "p_value_z = 2 * (1 - norm.cdf(abs(z_stat)))\n",
        "\n",
        "t_stat, p_value_t = ttest_1samp(sample, pop_mean)\n",
        "\n",
        "print(\"Sample Mean:\", sample_mean)\n",
        "print(f\"\\nZ-test (assuming known population std dev = {pop_std}):\")\n",
        "print(f\"Z-statistic = {z_stat:.4f}\")\n",
        "print(f\"P-value = {p_value_z:.4f}\")\n",
        "\n",
        "print(f\"\\nT-test (using sample std dev):\")\n",
        "print(f\"T-statistic = {t_stat:.4f}\")\n",
        "print(f\"P-value = {p_value_t:.4f}\")\n",
        "\n",
        "print(\"\\nInterpretation at alpha =\", alpha)\n",
        "if p_value_z < alpha:\n",
        "    print(\"Z-test: Reject null hypothesis (sample mean differs significantly)\")\n",
        "else:\n",
        "    print(\"Z-test: Fail to reject null hypothesis\")\n",
        "\n",
        "if p_value_t < alpha:\n",
        "    print(\"T-test: Reject null hypothesis (sample mean differs significantly)\")\n",
        "else:\n",
        "    print(\"T-test: Fail to reject null hypothesis\")\n"
      ],
      "metadata": {
        "id": "POZy9HgzyZ28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Write a Python function to calculate the confidence interval for a sample mean and explain its significance\n"
      ],
      "metadata": {
        "id": "rJWEiO6XysHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import t\n",
        "\n",
        "def confidence_interval(sample, confidence=0.95):\n",
        "    \"\"\"\n",
        "    Calculate the confidence interval for the sample mean.\n",
        "\n",
        "    Parameters:\n",
        "    - sample: list or numpy array of sample data\n",
        "    - confidence: confidence level (default 0.95 for 95% CI)\n",
        "\n",
        "    Returns:\n",
        "    - (lower_bound, upper_bound): tuple with the confidence interval limits\n",
        "    \"\"\"\n",
        "    n = len(sample)\n",
        "    mean = np.mean(sample)\n",
        "    std_err = np.std(sample, ddof=1) / np.sqrt(n)\n",
        "\n",
        "    t_crit = t.ppf((1 + confidence) / 2, df=n - 1)\n",
        "\n",
        "    margin_of_error = t_crit * std_err\n",
        "\n",
        "    lower_bound = mean - margin_of_error\n",
        "    upper_bound = mean + margin_of_error\n",
        "\n",
        "    return lower_bound, upper_bound\n",
        "\n",
        "np.random.seed(0)\n",
        "sample_data = np.random.normal(loc=50, scale=5, size=30)\n",
        "\n",
        "ci_lower, ci_upper = confidence_interval(sample_data, confidence=0.95)\n",
        "print(f\"95% Confidence Interval: ({ci_lower:.2f}, {ci_upper:.2f})\")\n"
      ],
      "metadata": {
        "id": "oIDujiSyyv1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Write a Python program to calculate the margin of error for a given confidence level using sample data\n"
      ],
      "metadata": {
        "id": "nQHEHABQy_7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import t\n",
        "\n",
        "def margin_of_error(sample, confidence=0.95):\n",
        "    \"\"\"\n",
        "    Calculate the margin of error for the sample mean at the given confidence level.\n",
        "\n",
        "    Parameters:\n",
        "    - sample: list or numpy array of sample data\n",
        "    - confidence: confidence level (default 0.95 for 95% confidence)\n",
        "\n",
        "    Returns:\n",
        "    - margin_of_error: float, the margin of error\n",
        "    \"\"\"\n",
        "    n = len(sample)\n",
        "    std_err = np.std(sample, ddof=1) / np.sqrt(n)\n",
        "\n",
        "    t_crit = t.ppf((1 + confidence) / 2, df=n - 1)\n",
        "\n",
        "    return t_crit * std_err\n",
        "\n",
        "np.random.seed(42)\n",
        "sample_data = np.random.normal(loc=100, scale=15, size=40)\n",
        "\n",
        "moe = margin_of_error(sample_data, confidence=0.95)\n",
        "print(f\"Margin of Error at 95% confidence: {moe:.3f}\")\n"
      ],
      "metadata": {
        "id": "wAgHBZkrzCjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Implement a Bayesian inference method using Bayes' Theorem in Python and explain the process\n"
      ],
      "metadata": {
        "id": "gP5qAQ4BzMdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bayes_theorem(prior, likelihood, false_positive_rate):\n",
        "    \"\"\"\n",
        "    Calculate the posterior probability P(D|T) using Bayes' Theorem.\n",
        "\n",
        "    Parameters:\n",
        "    - prior: P(D), prior probability of disease\n",
        "    - likelihood: P(T|D), probability of positive test given disease\n",
        "    - false_positive_rate: P(T|¬¨D), probability of positive test given no disease\n",
        "\n",
        "    Returns:\n",
        "    - posterior: P(D|T), updated probability of disease given positive test\n",
        "    \"\"\"\n",
        "    prior_neg = 1 - prior\n",
        "\n",
        "    total_prob_positive = likelihood * prior + false_positive_rate * prior_neg\n",
        "\n",
        "    posterior = (likelihood * prior) / total_prob_positive\n",
        "\n",
        "    return posterior\n",
        "\n",
        "\n",
        "print(f\"Prior probability of disease: {prior:.2%}\")\n",
        "print(f\"Posterior probability of disease given positive test: {posterior:.2%}\")\n"
      ],
      "metadata": {
        "id": "mKDkKImNzPj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Perform a Chi-square test for independence between two categorical variables in Python\n"
      ],
      "metadata": {
        "id": "A7qpjDeCzdDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "data = np.array([[30, 10],\n",
        "                 [20, 40]])\n",
        "\n",
        "df = pd.DataFrame(data, index=['Male', 'Female'], columns=['Yes', 'No'])\n",
        "print(\"Contingency Table:\")\n",
        "print(df)\n",
        "\n",
        "chi2, p, dof, expected = chi2_contingency(data)\n",
        "\n",
        "print(f\"\\nChi-square statistic: {chi2:.4f}\")\n",
        "print(f\"Degrees of freedom: {dof}\")\n",
        "print(f\"P-value: {p:.4f}\")\n",
        "\n",
        "print(\"\\nExpected frequencies:\")\n",
        "print(pd.DataFrame(expected, index=df.index, columns=df.columns))\n",
        "\n",
        "alpha = 0.05\n",
        "if p < alpha:\n",
        "    print(\"\\nResult: Reject the null hypothesis - variables are dependent (associated).\")\n",
        "else:\n",
        "    print(\"\\nResult: Fail to reject the null hypothesis - variables are independent.\")\n"
      ],
      "metadata": {
        "id": "2ZXI4IGqzgDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "13.Write a Python program to calculate the expected frequencies for a Chi-square test based on observed data"
      ],
      "metadata": {
        "id": "UQAqzNF_zs9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_expected_frequencies(observed):\n",
        "    \"\"\"\n",
        "    Calculate expected frequencies for Chi-square test of independence.\n",
        "\n",
        "    Parameters:\n",
        "    - observed: 2D numpy array of observed counts\n",
        "\n",
        "    Returns:\n",
        "    - expected: 2D numpy array of expected counts\n",
        "    \"\"\"\n",
        "    row_sums = observed.sum(axis=1).reshape(-1, 1)\n",
        "    col_sums = observed.sum(axis=0).reshape(1, -1)\n",
        "    total = observed.sum()\n",
        "\n",
        "    expected = (row_sums @ col_sums) / total\n",
        "    return expected\n",
        "\n",
        "print(\"Observed frequencies:\\n\", observed_data)\n",
        "print(\"\\nExpected frequencies:\\n\", expected_freq)\n"
      ],
      "metadata": {
        "id": "3V0ntJDvz0QQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. Perform a goodness-of-fit test using Python to compare the observed data to an expected distribution.\n"
      ],
      "metadata": {
        "id": "ZpiNeQrn0DWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import chisquare\n",
        "\n",
        "observed = np.array([50, 30, 20])\n",
        "\n",
        "expected = np.array([40, 40, 20])\n",
        "\n",
        "chi2_stat, p_value = chisquare(f_obs=observed, f_exp=expected)\n",
        "\n",
        "print(f\"Chi-square statistic: {chi2_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: Observed data do NOT fit the expected distribution.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: Observed data fit the expected distribution.\")\n"
      ],
      "metadata": {
        "id": "onmL2zRb0G4u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}